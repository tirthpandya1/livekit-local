Our LLM is Ollama running gemma3:4b for language model inference